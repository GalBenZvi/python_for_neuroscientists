{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 10 - 13.5.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Design Principles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous class discussed one of the most important aspects of writing software - testing. But testing is a \"mechanism\" used when writing code, it's not some high-level principle. This class will deal with a few important principles that should be kept in the back of your minds whenever you write a program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the ideas presented below are from Robert Martin's, AKA Uncle Bob, lectures and textbooks. He's one of the founding fathers of object-oriented design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Orthogonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases objects interact with one another. In the case of some `ProcessData` class, which might process some instances of a `Data` class, that can contain a couple of `Series` and metadata, for example, we can see how `ProcessData` communicates with the data inside the `Data` class, modifying it further. \n",
    "\n",
    "A preliminary design might look like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Data:\n",
    "    \"\"\" Simple container for DataFrames and their metadata \"\"\"\n",
    "    def __init__(self, arr1: np.ndarray, arr2: np.ndarray, date: float):\n",
    "            self.ser1 = pd.Series(arr1, dtype=np.uint8)\n",
    "            self.ser22 = pd.Series(arr2, dtype=np.int16)\n",
    "            self.metadata = dict(shape1=self.df1.shape,\n",
    "                                 shape2=self.df2.shape,\n",
    "                                 total=self.df1.shape[0] + self.df2.shape[0],\n",
    "                                 date=date)\n",
    "            \n",
    "class ProcessData:\n",
    "    \"\"\" Pipeline to process twin Data instances \"\"\"\n",
    "    def __init__(self, data1: Data, data2: Data):\n",
    "        self.data1 = data1\n",
    "        self.data2 = data2\n",
    "        self.result = []\n",
    "        self.metadata = dict(columns1=data1.columns,\n",
    "                             columns2=data2.columns,\n",
    "                             metadata=data1.metadata)\n",
    "        \n",
    "    def process(self):\n",
    "        self.result.extend([data1.x.sum(), data2.x.sum()])\n",
    "        self.result.append([data1.x.mean() + data2.y.mean()])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have here a `Data` class which serves as a container for two DataFrames that are logically connected. It also simplifies the access to some of the metadata contained with theses DataFrames.\n",
    "\n",
    "We also have a `ProcessData` class that uses the `Data` instances to calculate some statistical properties and keep them for later use.\n",
    "\n",
    "While this design works (which is important), it's flawed in the sense that the `ProcessData` object is very reliant on the implementation details of the `Data` class. When higher-level objects are dependent on specific attributes of some lower-level module, we need to perform Dependency Inversion. This decoupling process can also be called \"object orthogonality\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do a couple of major changes to our design which will solve, step by step, the design issues we encoutered.\n",
    "\n",
    "First we'll create a new `DataContainer` class that holds `Data` instances, and redefine the `Data` class more appropriately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    \"\"\" Simple container for DataFrames and their metadata \"\"\"\n",
    "    def __init__(self, arr1: np.ndarray, arr2: np.ndarray, date: float):\n",
    "            self._ser1 = pd.Series(arr1, dtype=np.uint8)\n",
    "            self._ser2 = pd.Series(arr2, dtype=np.int16)\n",
    "            self._metadata = dict(shape1=self.df1.shape,\n",
    "                                 shape2=self.df2.shape,\n",
    "                                 total=self.df1.shape[0] + self.df2.shape[0],\n",
    "                                 date=date)\n",
    "    @property\n",
    "    def data(self):\n",
    "        \"\"\" Returns the actual data variables as an iterable\"\"\"\n",
    "        result = [self._ser1, self._ser2]\n",
    "        return result\n",
    "    \n",
    "    @property\n",
    "    def metadata(self):\n",
    "        return self._metadata\n",
    "    \n",
    "    def sum(self):\n",
    "        return [x.sum() for x in self.data]\n",
    "    \n",
    "    \n",
    "class DataContainer:\n",
    "    \"\"\" Holds, in order, instances of Data \"\"\"\n",
    "    def __init__(self, datas):\n",
    "        self._data = []\n",
    "        self._metadata = {}\n",
    "        try:\n",
    "            for idx, data in enumerate(datas):\n",
    "                if isinstance(data, Data):\n",
    "                    self._data.append(data)\n",
    "                    self._metadata[idx] = data.metadata\n",
    "                else:\n",
    "                    raise TypeError(f\"TypeError: Data {data} isn't a 'Data' type.\")\n",
    "        except TypeError as e:\n",
    "            print(e)\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._data\n",
    "    \n",
    "    @property\n",
    "    def metadata(self):\n",
    "        return self._metadata\n",
    "    \n",
    "    def sum(self):\n",
    "        result = []\n",
    "        for data in self._data:\n",
    "            result.append(data.sum())\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First note the \"new technical term\": We introduce here the `@property` decorators. We'll discuss Python's decorators in the next class, but for now we only care about their practical aspect: If we define some method as a property, that keyword can be used like a regular attribute, except for the fact that it's immutable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original attribute: 2\n",
      "Attributes can be changed: 3\n",
      "------\n",
      "Using the method: 2\n",
      "And of course, it can't be changed (immutable).\n",
      "------\n",
      "As a property: 2\n",
      "AttributeError: can't set attribute - properties can't be changed.\n"
     ]
    }
   ],
   "source": [
    "class Trial:\n",
    "    def __init__(self):\n",
    "        self.two_as_attr = 2\n",
    "    \n",
    "    def two_as_method(self):\n",
    "        return 2\n",
    "    \n",
    "    @property\n",
    "    def two_as_prop(self):\n",
    "        return 2\n",
    "\n",
    "tr = Trial()\n",
    "\n",
    "# Changing attributes is possible:\n",
    "print(f\"The original attribute: {tr.two_as_attr}\")\n",
    "tr.two_as_attr = 3\n",
    "print(f\"Attributes can be changed: {tr.two_as_attr}\")\n",
    "print(\"------\")\n",
    "\n",
    "# Using the regular method requires brackets\n",
    "print(f\"Using the method: {tr.two_as_method()}\")\n",
    "print(\"And of course, it can't be changed (immutable).\")\n",
    "print(\"------\")\n",
    "\n",
    "# Using a property \"feels\" like using an attributes:\n",
    "print(f\"As a property: {tr.two_as_prop}\")  # no brackets\n",
    "try:\n",
    "    tr.two_as_prop = 3  # AttributeError\n",
    "except AttributeError as e:\n",
    "    print(f\"AttributeError: {e} - properties can't be changed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Properties are useful for one more reason (setters), which we'll examine in the next class.\n",
    "\n",
    "But besides this new, exciting feature of Python, what else has changed with the implementation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Data`:\n",
    "1. We redefined `Data`. The new object doesn't allow anyone from the outside to change the data it holds, it only allows for a \"view\" of the data. The use of properties ensure that once the object was created, the internal structure of the instance remains intact. The single underscore before the variable names also prevents direct access to the attribute.\n",
    "\n",
    "2. Furthermore, if we examine the `sum()` method, we see that it's now bound to the `Data` object itself. If we write it explicitly it makes senes: _The sum of the data is a bound method to our data - an intrinsic property of it._ If we every decide to change how our data is stored, the `sum()` method should change accordingly, but no other object will be affected.\n",
    "\n",
    "\n",
    "#### `DataContainer`:\n",
    "1. The new `DataContainer` class _doesn't really know_ what it's holding. All it cares is that they're `Data` instances. It doesn't peek inside the methods of the different `Data` instances.\n",
    "\n",
    "2. It doesn't allow access to the list of `Data` instances itself. It exposes a `data` property which returns the list. If we decide to change the internal implementation of `DataContainer`, users of this class wouldn't care as long as we keep the output of the `data` property similar. Even if the list is empty - it will always return something.\n",
    "\n",
    "Let's see the redefined implementation of the `ProcessData` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessData:\n",
    "    \"\"\" Pipeline to process twin Data instances \"\"\"\n",
    "    def __init__(self, datacont: DataContainer):\n",
    "        self.datacont = datacont\n",
    "        self.result = {}\n",
    "        self.metadata = datacont.metadata\n",
    "        \n",
    "    def process(self):\n",
    "        \"\"\" Mock processing pipeline \"\"\"\n",
    "        self.result['sum'] = self.datacont.sum()\n",
    "        means = [x.mean() for x in self.datacont.data]\n",
    "        self.result['mean'] = means\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet above is now much cleaner than the one we had beforehand. It uses the \"API\" of the `DataContainer` in two ways - either using a fully-featured `sum()` function, or by (securely) accessing the data using the `data` property and running non-standard processing on it - mean calculation in our case.}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downside is the added class - more code to write, more tests, more imports at the top. But the added value is tremendous. Think how easy it is to add new functionality into the pipeline. Everything is flexible, allowing to create a new `median()` function in the `DataContainer` class, for example. We can even change the internal structure of the `Data` class and still use the downstream class effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liskov Subtitution Principle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSP can be presented in several ways, and we'll choose the more straight-forward approach of just showing an example of when the principle is violated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say I wish to model a rectangle, just as we did in the first class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rectangle:\n",
    "    \"\"\" A very simple implementation just to prove a point \"\"\"\n",
    "    def __init__(self, point, x, y):\n",
    "        self.corner = point[0], point[1]\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def move(self, point):\n",
    "        \"\"\" Move the object to the point \"\"\"\n",
    "        self.corner = point\n",
    "        \n",
    "    def set_width(self, dx):\n",
    "        \"\"\" Change width to dx \"\"\"\n",
    "        self.x = dx\n",
    "    \n",
    "    def set_height(self, dy):\n",
    "        \"\"\" Change height to dy \"\"\"\n",
    "        self.y = dy        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the docstring says, above is a super-basic implementation of such a Rectangle. Take note of the two mutating functions that present a way to change the shape of the rectangle _independently._ This seems very logical when only dealing with a rectangle - each side truly is independent of the other.\n",
    "\n",
    "However, if we wish to reuse this class when modeling a Square via inheritance, we'll be facing quite a pickle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Square(Rectangle):\n",
    "    \"\"\" Simple circle, inheriting from Rectangle \"\"\"\n",
    "    def __init__(self, point, x):\n",
    "        super().__init__(point, x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square size: (10, 10)\n",
      "Square corner: (0, 0)\n"
     ]
    }
   ],
   "source": [
    "sq = Square((0, 0), 10)\n",
    "print(f\"Square size: {sq.x, sq.y}\")\n",
    "print(f\"Square corner: {sq.corner}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially this seems OK. We only require a single `x` input for a square, and we just pass it twice to the `Rectangle` constructor to create a squared rectangle.\n",
    "\n",
    "Even the `move()` method of the rectangle is helpful - we can move our square around without the need to redefine it.\n",
    "\n",
    "But the `set_X()` methods are an issue. We can't allow for users of our `Square` to modify the height and width of the square independently. If someone would only change the square's height, keeping its current width unchanged, it would make our `Square` not a true square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dimensions: (10, 20) - not a square.\n"
     ]
    }
   ],
   "source": [
    "sq.set_height(20)\n",
    "print(f\"New dimensions: {sq.x, sq.y} - not a square.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logically, and mathematically, a square _should_ inherit from a Rectangle. The simple mental model of the problem at hand is very clear with this inheritance relationship in mind. However, our implementation reaches a set back with might have not been able to predict in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSP claims that we should be able to replace instances of `Rectangle` with instances of `Square` without changing the correctness of the application. In this case we see that this substitution isn't possible, and so the principle breaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Limit the use of inheritance\n",
    "Only when we're completely positive that the use of inheritance will contribute to our application - by improving readability or reducing code repetitions - only then should we use it. It's an important tool to have as an object-oriented programmer, but one which should be used carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define a higher-level abstraction\n",
    "We could define a more abstract base class for both the rectangle and square, such as a `2DShape`. This class can have a `corner` attribute, and a few very basic methods like `move()`. This will change the definition of `Rectangle` to \n",
    "\n",
    "```python\n",
    "class Rectangle(TwoDShape):\n",
    "     # ...\n",
    "``` \n",
    "and `Square` to \n",
    "```python\n",
    "class Square(TwoDShape):\n",
    "     # ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Override methods of the base class\n",
    "We may simply override the implementation of one (or both) of the `set_X()` methods. The new implementation may raise a warning when trying to use it, pointing the user to the appropriate method, or it may raise a simple exception."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Addition of a precondition\n",
    "We can add to the `Rectangle` class a flag (=boolean attribute) called `stretchable`. Each `set_X()` methods then checks this flag, to see if the operation is allowed, before changing the width and height."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typestates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typestates are a way to enforce the state of our data\\application with strict types.\n",
    "\n",
    "\n",
    "Let's assume I have 24 human volunteers in combined a fMRI + questionnaire study. I keep them all in a single DataFrame for brevity and ease-of-use, but in effect they're in different stages of my experiment. A few were just recruited last week, and I haven't even set a date for our first meeting. A few others were already scanned in the magnet once, but still have to go through my second questionnaire session. \n",
    "\n",
    "My application monitors these students, alerts me of incoming meeting dates, and (of course) analyzes the results of the questionnaires and scans.\n",
    "\n",
    "The __correctness__ of this application can be enforced in many ways - tests, mock data, daily use - but here I choose to show another mechanism - typestates. The fact that the current status of each volunteer isn't specified with a simple string in a table, but is actually a different class altogether, is another way to make sure that I always receive the expected output from each method call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Helper types\n",
    "class Name:\n",
    "    \"\"\" First and last name \"\"\"\n",
    "    # Implementation omitted\n",
    "\n",
    "\n",
    "class Age:\n",
    "    \"\"\" Special age type \"\"\"\n",
    "    # Implementation omitted\n",
    "\n",
    "\n",
    "class FmriResult:\n",
    "    \"\"\" Results from an fMRI scan \"\"\"\n",
    "    # Implementation omitted\n",
    "\n",
    "\n",
    "# Volunteer types    \n",
    "class Volunteer:\n",
    "    \"\"\" Base class for all volunteers in my project \"\"\"\n",
    "    def __init__(self, name: Name, age: Age, call_date: datetime.time, vol_id: int):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.call_date = call_date\n",
    "        self.id = vol_id\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"{self.name}, age {self.age}, first called at {self.call_date}.\"\n",
    "        \n",
    "    def update_df(self, records: pd.DataFrame):\n",
    "        \"\"\" Add the instance to the dataframe containing the rest of the data \"\"\"\n",
    "        record = pd.DataFrame([self.name, self.age, self.call_date, \n",
    "                               self.id, self.metadata, type(self), copy.copy(self)])\n",
    "        records.append(record)\n",
    "        return records\n",
    "    \n",
    "    def remove_from_df(self, records: pd.DataFrame):\n",
    "        \"\"\" Remove the instance from the student records \"\"\"\n",
    "        idx = records.id == self.id\n",
    "        records.drop(idx, inplace=True)\n",
    "        return records\n",
    "\n",
    "    \n",
    "class PreScanOne(Volunteer):\n",
    "    \"\"\" Volunteer before the first session \"\"\"\n",
    "    loc = 0  # ordinal place in hierarchy\n",
    "    \n",
    "    def __init__(self, name: Name, age: Age, call_date: datetime.time, vol_id: int, \n",
    "                 scan_one_date: datetime.time):\n",
    "        super().__init__(name, age, call_date, vol_id)\n",
    "        self.metadata = dict(scan_one_date=scan_one_date)\n",
    "        \n",
    "    def advance(self, result: FmriResult, next_date: datetime.time):\n",
    "        \"\"\" Advance a PreScanOne to a PostScanOne \"\"\"\n",
    "        new = PostScanOne(self, result, next_date)\n",
    "        return new\n",
    "    \n",
    "\n",
    "class PostScanOne(Volunteer):\n",
    "    \"\"\" Volunteer after the first session \"\"\"\n",
    "    loc = 1\n",
    "    \n",
    "    def __init__(self, pre_volunteer: PreScanOne, scan_one_data: FmriResult, \n",
    "                 scan_two_date: datetime.time):\n",
    "        super().__init__(pre_volunteer.name, pre_volunteer.age, pre_volunteer.call_date, pre_volunteer.id)\n",
    "        self.metadata = pre_volunteer.metadata\n",
    "        self.metadata['scan_one_data'] = scan_one_data\n",
    "        self.metadata['scan_to_date'] = scan_two_date\n",
    "    \n",
    "    def advance(self, result: FmriResult, next_date: datetime.time):\n",
    "        \"\"\" Advance a PostScanOne to a PreScanTwo \"\"\"\n",
    "        new = PreScanTwo(self, result, next_date)\n",
    "        return new\n",
    "    \n",
    "    \n",
    "# Examples of generic methods that use this interface\n",
    "def advance_volunteer(old_vol, results: FmriResult, records: pd.DataFrame):\n",
    "    \"\"\" \n",
    "    Move volunteer to next step in the experiment, returning the new \n",
    "    instance and records.\n",
    "    \"\"\"\n",
    "    old_vol.remove_from_df(records)\n",
    "    new_vol = old_vol.advance(results, records)\n",
    "    new_vol.update_df(records)\n",
    "    return new_vol, records\n",
    "\n",
    "\n",
    "def process_data(records):\n",
    "    \"\"\" Run the same processing function over all fMRI data \"\"\"\n",
    "    results = []\n",
    "    for vol in records:\n",
    "        try:\n",
    "            results.append(vol.process_data)\n",
    "        except AttributeError:  # instance doesn't have data\n",
    "            pass\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is long, but interesting, so let's try to break it down.\n",
    "\n",
    "At the beginning we have a few help classes which I merely defined, but not implemented. These shouldn't look strange to you. We talked during class of how an `Age` type is an important example of defining our own types in a program, since it's neither an integer nor a floating point number.\n",
    "\n",
    "The second part is the most interesting. We have a base class called `Volunteer` which contains basic information which is common to all experiment volunteers. But it's actually more than that - it also defines the _interfaces_ between the classes, it forces the classes to have specific attributes that will comply to this protocol, linking their behavior together.\n",
    "\n",
    "The other two classes inherit from `Volunteer` and represent the first two steps in the \"Volunteer path\". The `loc` class variable signifies that. From phase one (`PreScanOne`( a volunteer can only advance forward (or drop out from the experiment) to step 2. And likewise from step 2 to 3 - you'll always find the same `.advance()` method that takes you to the next step, even though the implementation is slightly different. To handle the variability in the held data, we have the `metadata` attribute which can hold different parameters and datapoints.\n",
    "\n",
    "The last part shows how to use such an interface. We have a function that advances an instance of a class \"one step\" to the next phase. We have a function that runs some processing on the data held inside the instances, and we can have as many functions (and classes as we wish). It's completely extensible since the API is well-defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Concepts and Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, good and clear software design can be aided using unique Python features and packages. We'll review a few of the more prominent ones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Annotations and MyPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since version 3.6, Python allows this syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict\n",
    "\n",
    "def doer_of_stuffs(a: float, b: int, c: str = 'ccc') -> Tuple[str, Dict[int, float]]:\n",
    "    \"\"\"\n",
    "    Does stuff to a, b, and c.\n",
    "    Returns: A tuple of a string and a dictionary mapping ints to floats\n",
    "    \"\"\"\n",
    "    a_helper: float = a + 2\n",
    "    b_helper: float = b / 3\n",
    "    int_a = int(a_helper)\n",
    "    c2: str = c + c\n",
    "    return c2, {b: a_helper, int_a: b_helper}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a bit more verbose, these _type annotations_ make things clearer when dealing with large codebases. Knowing the defined type of your variables as they bounce around between modules and functions can help with the debugging process of your code tremendously.\n",
    "\n",
    "Moreover, modern IDEs like PyCharm and VSCode will alert you before you run the code of any possible type errors. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    a = 3  # integer\n",
    "    a /= 2  # now it's a float\n",
    "    arr = np.array([1, 2, 3])\n",
    "    \n",
    "    # ... lots of code here\n",
    "    \n",
    "    b = arr[a]  # TypeError - cannot index with a float variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyCharm and VSCode will mark this `arr[a]` expression and try to prevent you from running this code. \n",
    "\n",
    "A more wholesome approach is `mypy`, which was developed in Dropbox, a company very reliant on its Python-based product. When the Dropbox codebase increased in size, its engineers wanted to keep using Python due to its amazing features, but avoid the problems that come with a dynamically-typed language. Thus, `mypy` was born. In essence, it's a command-line tool that runs type checks on the entirety of your code base, verifying the type-correctness of your application. In many places a clean `mypy` error log is required before committing changes to the code base.\n",
    "\n",
    "`mypy` supports both comment-based type annotations for older versions of Python (Dropbox, as of early 2018, is still using Python 2.7) and the new style of type annotations shown above. It can also generate type annotations on the fly, using `PyAnnotate`, while you run your application.\n",
    "\n",
    "An example can be found in the `mypy_demo` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enumerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python added enumeration support in Python 3.4, and it's starting to pop-up more and more in new code bases. An enumeration is a list of discrete possible values. Assuming I have a simple addition function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_add(a, b, add=True):\n",
    "    \"\"\" Simple addition\\subtraction \"\"\"\n",
    "    return a + b if add else a - b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of possible values for `a` and `b` is endless, so these cannot be enumerated. The `add` keyword is called a \"flag\", since it has two possible values - `True` and `False`. It's an enumeration of two possible values.\n",
    "\n",
    "When we have more than two options, or when our two options aren't simply booleans, we can use an enumeration. Here's a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',\n",
       "               '2018-01-05', '2018-01-06', '2018-01-07', '2018-01-08',\n",
       "               '2018-01-09', '2018-01-10', '2018-01-11', '2018-01-12',\n",
       "               '2018-01-13', '2018-01-14', '2018-01-15', '2018-01-16',\n",
       "               '2018-01-17', '2018-01-18', '2018-01-19', '2018-01-20',\n",
       "               '2018-01-21', '2018-01-22', '2018-01-23', '2018-01-24',\n",
       "               '2018-01-25', '2018-01-26', '2018-01-27', '2018-01-28',\n",
       "               '2018-01-29', '2018-01-30', '2018-01-31', '2018-02-01',\n",
       "               '2018-02-02', '2018-02-03', '2018-02-04', '2018-02-05',\n",
       "               '2018-02-06', '2018-02-07', '2018-02-08', '2018-02-09',\n",
       "               '2018-02-10', '2018-02-11', '2018-02-12', '2018-02-13',\n",
       "               '2018-02-14', '2018-02-15', '2018-02-16', '2018-02-17',\n",
       "               '2018-02-18', '2018-02-19', '2018-02-20', '2018-02-21',\n",
       "               '2018-02-22', '2018-02-23', '2018-02-24', '2018-02-25',\n",
       "               '2018-02-26', '2018-02-27', '2018-02-28', '2018-03-01',\n",
       "               '2018-03-02', '2018-03-03', '2018-03-04', '2018-03-05',\n",
       "               '2018-03-06', '2018-03-07', '2018-03-08', '2018-03-09',\n",
       "               '2018-03-10', '2018-03-11', '2018-03-12', '2018-03-13',\n",
       "               '2018-03-14', '2018-03-15', '2018-03-16', '2018-03-17',\n",
       "               '2018-03-18', '2018-03-19', '2018-03-20', '2018-03-21',\n",
       "               '2018-03-22', '2018-03-23', '2018-03-24', '2018-03-25',\n",
       "               '2018-03-26', '2018-03-27', '2018-03-28', '2018-03-29',\n",
       "               '2018-03-30', '2018-03-31', '2018-04-01', '2018-04-02',\n",
       "               '2018-04-03', '2018-04-04', '2018-04-05', '2018-04-06',\n",
       "               '2018-04-07', '2018-04-08', '2018-04-09', '2018-04-10'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "rng = pd.date_range('1/1/2018',periods=100, freq='D')  # 'D' is days\n",
    "rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31', '2018-04-30',\n",
       "               '2018-05-31', '2018-06-30', '2018-07-31', '2018-08-31',\n",
       "               '2018-09-30', '2018-10-31', '2018-11-30', '2018-12-31',\n",
       "               '2019-01-31', '2019-02-28', '2019-03-31', '2019-04-30',\n",
       "               '2019-05-31', '2019-06-30', '2019-07-31', '2019-08-31',\n",
       "               '2019-09-30', '2019-10-31', '2019-11-30', '2019-12-31',\n",
       "               '2020-01-31', '2020-02-29', '2020-03-31', '2020-04-30',\n",
       "               '2020-05-31', '2020-06-30', '2020-07-31', '2020-08-31',\n",
       "               '2020-09-30', '2020-10-31', '2020-11-30', '2020-12-31',\n",
       "               '2021-01-31', '2021-02-28', '2021-03-31', '2021-04-30',\n",
       "               '2021-05-31', '2021-06-30', '2021-07-31', '2021-08-31',\n",
       "               '2021-09-30', '2021-10-31', '2021-11-30', '2021-12-31',\n",
       "               '2022-01-31', '2022-02-28', '2022-03-31', '2022-04-30',\n",
       "               '2022-05-31', '2022-06-30', '2022-07-31', '2022-08-31',\n",
       "               '2022-09-30', '2022-10-31', '2022-11-30', '2022-12-31',\n",
       "               '2023-01-31', '2023-02-28', '2023-03-31', '2023-04-30',\n",
       "               '2023-05-31', '2023-06-30', '2023-07-31', '2023-08-31',\n",
       "               '2023-09-30', '2023-10-31', '2023-11-30', '2023-12-31',\n",
       "               '2024-01-31', '2024-02-29', '2024-03-31', '2024-04-30',\n",
       "               '2024-05-31', '2024-06-30', '2024-07-31', '2024-08-31',\n",
       "               '2024-09-30', '2024-10-31', '2024-11-30', '2024-12-31',\n",
       "               '2025-01-31', '2025-02-28', '2025-03-31', '2025-04-30',\n",
       "               '2025-05-31', '2025-06-30', '2025-07-31', '2025-08-31',\n",
       "               '2025-09-30', '2025-10-31', '2025-11-30', '2025-12-31',\n",
       "               '2026-01-31', '2026-02-28', '2026-03-31', '2026-04-30'],\n",
       "              dtype='datetime64[ns]', freq='M')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = pd.date_range('1/1/2018',periods=100, freq='M')  # it can also be 'M'\n",
    "rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the possible values for the `freq` keyword? Day is `D`, month is `M`, Year will probably be `Y`. Are there any more keywords? Will `d` also work, or do I have to use capital `D`? Actually, checking the [official](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.date_range.html) documentation doesn't result in anything too useful.\n",
    "\n",
    "This is where enumerations come into play. This could've been simpler if we could only choose a value from a list of possible values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'DateRangeFreq'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-1ddc1fd91d3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'years'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mrng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1/1/2018'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mperiods\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDateRangeFreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# doesn't actually work...\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'DateRangeFreq'"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class DateRangeFreq(Enum):\n",
    "    D = 'days'\n",
    "    M = 'months'\n",
    "    Y = 'years'\n",
    "\n",
    "rng = pd.date_range('1/1/2018',periods=100, freq=pd.DateRangeFreq.D)  # doesn't actually work..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were unsure of the available parameters, we could import the `DateRangeFreq` object and inspect its possible values. As you can see, each key has a value associated with it. This value can be an integer, string or event a Python object.\n",
    "\n",
    "Enumerations are still hard to find in the Python ecosystem. They're a recent addition, and Pythonistas are used to typing strings in their function parameters, and not enumerations. But in many other languages with native enum support these data structures are very frequent for this use case, as well as others. If you're writing a piece of code that is intended to a Python 3.4+ audience, I suggest you use enumerations liberally in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `attrs` - Classes without boilerplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python classes are extremely useful, but they're also pretty verbose. They require you to write a lot of code for very basic operations.\n",
    "\n",
    "For example, in the the `__init__()` method you have to go through each variable in the function signature and assign it to your own value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example:\n",
    "    def __init__(self, param1, param2, param3, param4):\n",
    "        self.param1 = param1\n",
    "        self.param2 = param2\n",
    "        self.param3 = param3\n",
    "        self.param4 = param4\n",
    "    \n",
    "    def my_method(self):\n",
    "        \"\"\" Do stuff \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So many lines of repetitive code doing basically nothing. I didn't assert the types of the variables, I didn't do some basic pre-processing - this is called \"boilerplate\" code. Python requires me to write these tedious lines every time I create a class, and when classes get bigger and bigger, these assignments can be a hassle to write."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`attrs` to the rescue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attr\n",
    "from attr.validators import instance_of\n",
    "\n",
    "\n",
    "@attr.s\n",
    "class ExampleTwo:\n",
    "    param1 = attr.ib(validator=instance_of(int))\n",
    "    param2 = attr.ib(validator=instance_of(float))\n",
    "    param3 = attr.ib(default='no')\n",
    "    param4 = attr.ib(default=attr.Factory(list))\n",
    "    \n",
    "    def my_method(self):\n",
    "        \"\"\" Do stuff \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. No `__init__` is required, each `paramX` variable is already assigned to `self.paramX`. It also allows the addition of validators, default values, converter functions (not shown), and it even implements the comparison methods (`__eq__`, `__gt__`, etc.) for you. It has a ton of other useful features which I won't go into right now, but you can be sure that it's a package worth using.\n",
    "\n",
    "I can testify that 95% of classes I write today are `attrs` classes, and so do many other fellow Pythonistas. I encourage you to read the [official documentation](http://www.attrs.org/en/stable/?badge=stable) and start using it ASAP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality analysis and units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with numbers that have units, it's usually a good idea to keep the physical quantity assigned to that value as close as possible.\n",
    "\n",
    "When you're measuring the local field potential using some electrode array, it's good practice to verify that throughout the entirety of your processing pipeline, the voltage values aren't divided by a number with units of time, because units of _[Volts] / [seconds]_ usually have no physical meaning. It can also help you assert that your dF/F calculation indeed has natural units, and not some other arbitrary units.\n",
    "\n",
    "There are many options in the Python world for dimensionality analysis. If you're using Python to write symbolic math and solve equations, I suggest you use SymPy's `physics.units` module. Else - use `pint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "3.04 meter"
      ],
      "text/latex": [
       "$3.04\\ \\mathrm{meter}$"
      ],
      "text/plain": [
       "<Quantity(3.04, 'meter')>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pint\n",
    "\n",
    "\n",
    "ureg = pint.UnitRegistry()\n",
    "3 * ureg.meter + 4 * ureg.cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67840601 0.41680269 0.03569134 0.15617332 0.08101041 0.61858173 0.07591067 0.9391682  0.87775667 0.85875565 0.57915854 0.2985855 0.02239399 0.89577427 0.98684997 0.97975409 0.67309812 0.37162258 0.7719006  0.94962064 0.1181541  0.4552931  0.23393877 0.3822539 0.51241471 0.53755886 0.61827535 0.4350629  0.7268777  0.41257104 0.45446691 0.22042157 0.81388193 0.48407141 0.79956398 0.9360064 0.16081747 0.330716   0.00854326 0.04916125 0.66139035 0.69787212 0.74412695 0.24824785 0.90420234 0.47109738 0.73362357 0.24076135 0.90065602 0.89628194 0.17025071 0.62822956 0.86413525 0.94979033 0.72284429 0.46424103 0.55754662 0.75681794 0.82981382 0.54200402 0.29357256 0.96331112 0.21272206 0.70698981 0.44695428 0.73939125 0.59775033 0.35856208 0.18263938 0.42416676 0.93361213 0.88421459 0.93858066 0.71897601 0.61245747 0.16123439 0.30849112 0.88801092 0.52152472 0.08118126 0.44950426 0.30234981 0.24917469 0.72929148 0.35612704 0.10440059 0.33538699 0.00425218 0.53947961 0.7912409 0.81694805 0.55827601 0.09050347 0.36063374 0.45507281 0.10446237 0.32305471 0.15093095 0.82589829 0.78933149] volt\n"
     ]
    }
   ],
   "source": [
    "measures = ureg.Quantity(np.random.random(100), 'volts')\n",
    "print(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.35681202 0.83360537 0.07138268 0.31234664 0.16202082 1.23716346 0.15182134 1.8783364  1.75551334 1.71751131 1.15831708 0.597171 0.04478798 1.79154855 1.97369993 1.95950817 1.34619624 0.74324516 1.54380121 1.89924128 0.2363082  0.9105862  0.46787754 0.76450779 1.02482943 1.07511772 1.23655069 0.8701258  1.4537554  0.82514209 0.90893382 0.44084315 1.62776385 0.96814283 1.59912796 1.87201281 0.32163494 0.661432   0.01708652 0.09832251 1.3227807  1.39574425 1.4882539  0.4964957  1.80840468 0.94219475 1.46724714 0.4815227 1.80131203 1.79256387 0.34050143 1.25645911 1.72827051 1.89958065 1.44568859 0.92848205 1.11509323 1.51363588 1.65962764 1.08400803 0.58714512 1.92662224 0.42544411 1.41397962 0.89390855 1.47878251 1.19550066 0.71712415 0.36527875 0.84833353 1.86722425 1.76842919 1.87716132 1.43795202 1.22491494 0.32246879 0.61698224 1.77602185 1.04304945 0.16236252 0.89900852 0.60469961 0.49834938 1.45858296 0.71225407 0.20880118 0.67077397 0.00850436 1.07895922 1.58248179 1.63389611 1.11655202 0.18100694 0.72126749 0.91014562 0.20892474 0.64610941 0.30186189 1.65179658 1.57866299] volt\n"
     ]
    }
   ],
   "source": [
    "print(measures * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<UnitsContainer({'[current]': 1.0})>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amps = measures / (2 * ureg.ohm)  # I = V/R\n",
    "amps.dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "DimensionalityError",
     "evalue": "Cannot convert from 'volt / ohm' ([current]) to 'second' ([time])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDimensionalityError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-2e1934a34b2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mamps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seconds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\general\\lib\\site-packages\\pint\\quantity.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, other, *contexts, **ctx_kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_units_container\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_REGISTRY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mmagnitude\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_magnitude_not_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mctx_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagnitude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\general\\lib\\site-packages\\pint\\quantity.py\u001b[0m in \u001b[0;36m_convert_magnitude_not_inplace\u001b[1;34m(self, other, *contexts, **ctx_kwargs)\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_REGISTRY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_magnitude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_REGISTRY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_magnitude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_convert_magnitude\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mctx_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\general\\lib\\site-packages\\pint\\registry.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, value, src, dst, inplace)\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_dimensionality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\general\\lib\\site-packages\\pint\\registry.py\u001b[0m in \u001b[0;36m_convert\u001b[1;34m(self, value, src, dst, inplace)\u001b[0m\n\u001b[0;32m   1212\u001b[0m                 \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_magnitude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_units\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1214\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mContextRegistry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_compatible_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_or_system\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\general\\lib\\site-packages\\pint\\registry.py\u001b[0m in \u001b[0;36m_convert\u001b[1;34m(self, value, src, dst, inplace)\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msrc_offset_units\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdst_offset_units\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 937\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNonMultiplicativeRegistry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m         \u001b[0msrc_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_dimensionality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\general\\lib\\site-packages\\pint\\registry.py\u001b[0m in \u001b[0;36m_convert\u001b[1;34m(self, value, src, dst, inplace, check_dimensionality)\u001b[0m\n\u001b[0;32m    706\u001b[0m             \u001b[1;31m# then the conversion cannot be performed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msrc_dim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdst_dim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mDimensionalityError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[1;31m# Here src and dst have only multiplicative units left. Thus we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDimensionalityError\u001b[0m: Cannot convert from 'volt / ohm' ([current]) to 'second' ([time])"
     ]
    }
   ],
   "source": [
    "amps.to('seconds')  # DimensionalityError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some projects this can be a pretty big overkill, but for others this can save many \"silent\" bugs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design vs. Productivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start exercising, one important note to remember: There's a thin line between under- and over-engineering. Very small scripting projects require almost no engineering at all. This might mean that after you gain a few extra months of experience in Python, the structure of code for a small scripting job in Python might be obvious for you right from the get-go. You'll know which data structures you'll have, whether or not you'll need a class or two, and how the user interface might go.\n",
    "\n",
    "On the other hand, large applications which span at least a few thousands lines of code will always need _some_ form of pre-planning. It would be senseless not to write out a diagram of the main modules in your code and their interfaces. One can consider this to be common knowledge, or a simple programmer's instinct. Just like architects sit down and plan for months in advance the construct they're about to create, programmers should spell out the architecture of their own programs. In no way will this guarantee you'll get the architecture right in the first time, but the design might serve as good building blocks when you start the refactoring process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems mostly occur when you write medium-sized scripts, up to a couple thousand lines. These scripts usually start out small - a few functions that deal with file I/O and display of data - but can grow quite quickly once you start adding functionality. When the script was short you probably didn't even write tests, since you were sure you're handling some insignificant piece of code, and now it starts biting back at you.\n",
    "\n",
    "It's hard to write rules for these occasions. When someone asks me for improved functionality on some short script I wrote, I sometimes tell them it will take more time than I think it should, since I want to devote time for refactoring of the code, to make the new functionality feel more natural inside it.\n",
    "\n",
    "It's also good practice to write use classes to bind data and methods, even when you think they might be overkill. It's much easier to expand the functionality of classes than of an assortment of functions."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:general]",
   "language": "python",
   "name": "conda-env-general-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
